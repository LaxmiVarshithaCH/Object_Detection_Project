# ğŸ§  Object Detection Project

This project focuses on building a custom object detection model using the YOLOv5 architecture. The model is trained to detect specific objects from images and videos and can be used for applications like real-time detection, automation, and surveillance.

---

## ğŸ“Œ Table of Contents

- [ğŸ” Overview](#-overview)
- [âœ… Features](#-features)
- [âš™ï¸ Installation](#ï¸-installation)
- [ğŸš€ How to Use](#-how-to-use)
- [ğŸ“‚ Dataset Structure](#-dataset-structure)
- [ğŸ‹ï¸â€â™‚ï¸ Training Details](#ï¸-training-details)
- [ğŸ“Š Results](#-results)
- [ğŸ–¼ï¸ Example Outputs](#-example-outputs)
- [ğŸ™‹â€â™€ï¸ Contributors](#-contributors)
- [ğŸ“„ License](#-license)
- [ğŸ“¬ Feedback](#-feedback)

---

## ğŸ” Overview

This project demonstrates:

- Dataset preparation for object detection
- Model training using YOLOv5
- Result analysis through loss/mAP curves
- Detection on new unseen images

The notebook `object_detector.ipynb` contains the complete pipeline.

---

## âœ… Features

- ğŸ“¦ Custom object detection
- ğŸ“ˆ Real-time training visualization
- ğŸ–¼ï¸ Supports inference on new images
- ğŸ”§ Easy to extend and fine-tune
- ğŸ“ Exports results in image and CSV format

---

## âš™ï¸ Installation

### 1. Clone this Repository


git clone https://github.com/LaxmiVarshithaCH/Object_Detection_Project.git
cd Object_Detection_Project


### 2. Install YOLOv5 and Dependencies

git clone https://github.com/ultralytics/yolov5
cd yolov5
pip install -r requirements.txt
âœ… Ensure Python 3.8+ and PyTorch are installed on your system.

## ğŸš€ How to Use

### 1. Open the Notebook
Launch Jupyter Notebook or VS Code and open object_detector.ipynb.

### 2. Train the Model
Define the dataset path and number of classes

Start training using YOLOv5 commands in the notebook

### 3. Run Inference
Upload a new image

Run the detection cell

Get bounding boxes and class labels on the image

## ğŸ“‚ Dataset Structure
<pre> dataset/ â”œâ”€â”€ images/ â”‚ â”œâ”€â”€ train/ â”‚ â””â”€â”€ val/ â”œâ”€â”€ labels/ â”‚ â”œâ”€â”€ train/ â”‚ â””â”€â”€ val/ </pre>

Each label file should follow YOLO format:
<class_id> <x_center> <y_center> <width> <height>


## ğŸ‹ï¸â€â™‚ï¸ Training Details
| Parameter     | Value                                                  |
| ------------- | ------------------------------------------------------ |
| Model         | YOLOv5s                                                |
| Epochs        | 100 (configurable)                                     |
| Batch size    | 16                                                     |
| Image size    | 640x640                                                |
| Optimizer     | SGD or Adam                                            |
| Loss Function | YOLO Loss (Bounding box + Objectness + Classification) |


## ğŸ“Š Results
Training metrics are saved in:

runs/train/exp/results.png â€” Loss, precision, recall, mAP

runs/train/exp/results.csv â€” Epoch-wise logs

Example:
| Metric    | Value |
| --------- | ----- |
| mAP\@0.5  | 0.89  |
| Precision | 0.92  |
| Recall    | 0.87  |


## ğŸ–¼ï¸ Example Outputs
| Input Image                | Output with Detections       |
| -------------------------- | ---------------------------- |
| ![myimage](https://github.com/user-attachments/assets/d556c770-5f5b-4366-896f-fbf8ca135a4e) | ![download (1)](https://github.com/user-attachments/assets/d536bd72-774e-4f8a-a963-2aabbeb1f8af) |


## ğŸ™‹â€â™€ï¸ Contributors
CHENNUPALLI LAXMI VARSHITHA
GitHub: @LaxmiVarshithaCH

## ğŸ“„ License
This project is licensed under the MIT License.
Feel free to use, modify, and distribute it for personal or commercial use.

## ğŸ“¬ Feedback
Have suggestions or improvements?
Feel free to open an issue or submit a pull request. Happy coding! ğŸš€
